import os
import json
from pathlib import Path
from datetime import datetime, timedelta, date
from collections import defaultdict
import urllib3
import threading
import time
from zoneinfo import ZoneInfo

from fastapi import FastAPI, Request
from dotenv import load_dotenv
import requests

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

app = FastAPI()

# –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å –ù–æ–≤–æ–∫—É–∑–Ω–µ—Ü–∫–∞ (UTC+7)
NOVOKUZNETSK_TZ = ZoneInfo("Asia/Novokuznetsk")

# ==========================
#  –ü–ï–†–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–¨ (JSON, 90 –¥–Ω–µ–π)
# ==========================

DATA_FILE = os.getenv("DATA_FILE", "./moves_by_date.json")
DATA_RETENTION_DAYS = int(os.getenv("DATA_RETENTION_DAYS", "90"))

data_lock = threading.Lock()

# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤ –ø–∞–º—è—Ç–∏:
# moves_by_date["YYYY-MM-DD"]["–§–ò–û"][(from_col, to_col)] = count
moves_by_date: dict = {}


def _prune_old_dates(store: dict, retention_days: int) -> None:
    """–£–¥–∞–ª—è–µ—Ç –¥–∞—Ç—ã —Å—Ç–∞—Ä—à–µ retention_days (–ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—é –ù–æ–≤–æ–∫—É–∑–Ω–µ—Ü–∫–∞)."""
    cutoff = (datetime.now(NOVOKUZNETSK_TZ).date() - timedelta(days=retention_days))
    for dstr in list(store.keys()):
        try:
            d = datetime.strptime(dstr, "%Y-%m-%d").date()
        except Exception:
            continue
        if d < cutoff:
            store.pop(dstr, None)


def load_moves_from_json() -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç moves_by_date –∏–∑ JSON (–µ—Å–ª–∏ –µ—Å—Ç—å)."""
    path = Path(DATA_FILE)
    if not path.exists():
        return {}

    try:
        with path.open("r", encoding="utf-8") as f:
            raw = json.load(f)
    except Exception as e:
        print(f"[PERSIST] ‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å {DATA_FILE}: {e}")
        return {}

    store = {}
    if isinstance(raw, dict):
        for dstr, users in raw.items():
            if not isinstance(users, dict):
                continue
            store[dstr] = {}
            for user, routes in users.items():
                if not isinstance(routes, dict):
                    continue
                dd = defaultdict(int)
                for route_str, count in routes.items():
                    if not isinstance(route_str, str):
                        continue
                    if "‚Üí" in route_str:
                        from_col, to_col = [p.strip() for p in route_str.split("‚Üí", 1)]
                    else:
                        from_col, to_col = route_str.strip(), ""
                    try:
                        dd[(from_col, to_col)] += int(count)
                    except Exception:
                        pass
                store[dstr][user] = dd

    _prune_old_dates(store, DATA_RETENTION_DAYS)
    return store


def save_moves_to_json(store: dict) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç moves_by_date –≤ JSON –∞—Ç–æ–º–∞—Ä–Ω–æ."""
    path = Path(DATA_FILE)
    path.parent.mkdir(parents=True, exist_ok=True)

    raw = {}
    for dstr, users in store.items():
        raw[dstr] = {}
        for user, routes in users.items():
            raw[dstr][user] = {}
            for (from_col, to_col), count in routes.items():
                raw[dstr][user][f"{from_col} ‚Üí {to_col}"] = int(count)

    tmp = path.with_suffix(path.suffix + ".tmp")
    try:
        with tmp.open("w", encoding="utf-8") as f:
            json.dump(raw, f, ensure_ascii=False, indent=2)
        tmp.replace(path)
    except Exception as e:
        print(f"[PERSIST] ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {DATA_FILE}: {e}")
        try:
            if tmp.exists():
                tmp.unlink()
        except Exception:
            pass


def persist_now() -> None:
    _prune_old_dates(moves_by_date, DATA_RETENTION_DAYS)
    save_moves_to_json(moves_by_date)


# ==========================
#  –ö–ê–õ–ï–ù–î–ê–†–¨ (–≤—ã—Ö–æ–¥–Ω—ã–µ/–ø—Ä–∞–∑–¥–Ω–∏–∫–∏)
# ==========================

# –ü—Ä–∞–∑–¥–Ω–∏–∫–∏ –±–µ—Ä—ë–º –∏–∑ env HOLIDAYS="YYYY-MM-DD,YYYY-MM-DD,..."
def load_holidays() -> set[str]:
    raw = os.getenv("HOLIDAYS", "").strip()
    if not raw:
        return set()
    return {p.strip() for p in raw.split(",") if p.strip()}


HOLIDAYS = load_holidays()


def now_nsk() -> datetime:
    return datetime.now(NOVOKUZNETSK_TZ)


def date_to_str(d: date) -> str:
    return d.strftime("%Y-%m-%d")


def is_weekend(d: date) -> bool:
    return d.weekday() >= 5  # 5=Saturday,6=Sunday


def is_holiday(d: date) -> bool:
    return date_to_str(d) in HOLIDAYS


def is_workday(d: date) -> bool:
    return (not is_weekend(d)) and (not is_holiday(d))


def prev_workday(from_date: date) -> date:
    """–ü–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å –î–û from_date (–Ω–µ –≤–∫–ª—é—á–∞—è from_date)."""
    d = from_date - timedelta(days=1)
    while not is_workday(d):
        d -= timedelta(days=1)
    return d


def today_str() -> str:
    return now_nsk().strftime("%Y-%m-%d")


# ==========================
#  –°–õ–û–í–ê–†–¨ –ö–û–õ–û–ù–û–ö
# ==========================

COLUMN_NAMES = {
    # –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫
    5474955: "–í—Ö–æ–¥—è—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞",
    5474956: "–ó–∞–ø—Ä–æ—Å–∏—Ç—å –¢–û–ü–û",
    5524513: "–û–∂–∏–¥–∞–Ω–∏–µ –¢–û–ü–û",
    5474972: "–ó–∞–ø—Ä–æ—Å–∏—Ç—å –¢–£ —É –†–°–û",
    5485743: "WIP –û–ñ–ò–î–ê–ù–ò–ï",
    5474973: "–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ì–ü–ó–£",
    5474974: "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—á–∞–ª—å–Ω–∏–∫–∞ –æ—Ç–¥–µ–ª–∞",
    5474975: "–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –†–°–û,—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è)",
    5542289: "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ì–∞–±–∏–¥—É–ª–∏–Ω–∞ –†.–†. (–≥—Ä–∞–¥–ø–ª–∞–Ω—ã)",
    5474976: "–ü–æ–¥–ø–∏—Å–∞–Ω–∏–µ",
    5474977: "–í–Ω–µ—Å—Ç–∏ –≤ –ì–ò–°–û–ì–î (–≥—Ä–∞–¥–ø–ª–∞–Ω—ã)",
    5474978: "–í–Ω–µ—Å—Ç–∏ –≤ –ò–°–û–ì–î –∏ –∞—Ä—Ö–∏–≤",

    # –û—Ç–∫–∞–∑—ã
    5474950: "–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç–∫–∞–∑",
    5577124: "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ì–∞–±–∏–¥—É–ª–∏–Ω–∞ –†.–†. (–æ—Ç–∫–∞–∑—ã)",
    5474965: "–í–Ω–µ—Å—Ç–∏ –≤ –ì–ò–°–û–ì–î (–æ—Ç–∫–∞–∑—ã)",
    5474969: "–í–Ω–µ—Å—Ç–∏ –≤ –ò–°–û–ì–î",
}


def get_column_name(column_id: int) -> str:
    return COLUMN_NAMES.get(column_id, f"–ö–æ–ª–æ–Ω–∫–∞ {column_id}")


# ==========================
#  TELEGRAM
# ==========================

def send_telegram_report(text: str) -> bool:
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        print("[WARNING] ========== TELEGRAM –ù–ï –ù–ê–°–¢–†–û–ï–ù ==========")
        print(f"[WARNING] TELEGRAM_TOKEN —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {TELEGRAM_TOKEN is not None}")
        print(f"[WARNING] TELEGRAM_CHAT_ID –∑–Ω–∞—á–µ–Ω–∏–µ: {TELEGRAM_CHAT_ID}")
        return False

    url = f"https://149.154.167.220/bot{TELEGRAM_TOKEN}/sendMessage"
    headers = {"Host": "api.telegram.org"}

    try:
        response = requests.post(
            url,
            data={"chat_id": TELEGRAM_CHAT_ID, "text": text},
            headers=headers,
            timeout=10,
            verify=False
        )
        if response.status_code == 200:
            print("[TELEGRAM] ‚úÖ –û—Ç—á—ë—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
            return True
        print(f"[TELEGRAM] ‚ùå –û—à–∏–±–∫–∞: HTTP {response.status_code} | {response.text[:300]}")
        return False
    except Exception as e:
        print(f"[ERROR] –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram: {e}")
        return False


# ==========================
#  –£–ü–†–ê–í–õ–ï–ù–ß–ï–°–ö–ò–ô –û–¢–ß–Å–¢ (–ü–æ—Ç–æ–∫)
# ==========================

METRICS_ORDER = [
    "primary_intake",
    "rso_requests_done",
    "gpzu_prepared",
    "refusals_prepared",
    "head_checked",
    "gabidullina_checked",
    "gpzu_signed",
    "isogd_added",
]

METRICS = {
    # 1. –≤–Ω–µ—Å–µ–Ω—ã –≤ –∫–∞–π—Ç–µ–Ω –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞:
    # –ø–æ–ø–∞–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –≤ "–ó–∞–ø—Ä–æ—Å–∏—Ç—å –¢–û–ü–û" –ò–õ–ò "–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç–∫–∞–∑" (–æ–±—ä–µ–¥–∏–Ω—è–µ–º)
    "primary_intake": {
        "name": "–ü—Ä–∏–Ω—è—Ç–æ –≤ —Ä–∞–±–æ—Ç—É (–ø–µ—Ä–≤–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)",
        "column_ids": [5474956, 5474950],
    },

    # 2. –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –∑–∞–ø—Ä–æ—Å—ã –≤ –†–°–û: –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ WIP –û–ñ–ò–î–ê–ù–ò–ï
    "rso_requests_done": {
        "name": "–í—ã–ø–æ–ª–Ω–µ–Ω—ã –∑–∞–ø—Ä–æ—Å—ã –≤ –†–°–û",
        "column_ids": [5485743],
    },

    # 3. –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –≥—Ä–∞–¥–ø–ª–∞–Ω—ã: –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—á–∞–ª—å–Ω–∏–∫–∞ –æ—Ç–¥–µ–ª–∞"
    "gpzu_prepared": {
        "name": "–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –ì–ü–ó–£",
        "column_ids": [5474974],
    },

    # 4. –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –æ—Ç–∫–∞–∑—ã: –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ì–∞–±–∏–¥—É–ª–∏–Ω–∞ –†.–†. (–æ—Ç–∫–∞–∑—ã)"
    "refusals_prepared": {
        "name": "–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –æ—Ç–∫–∞–∑—ã",
        "column_ids": [5577124],
    },

    # 5. –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –ì–ü–ó–£ –Ω–∞—á–∞–ª—å–Ω–∏–∫–æ–º –æ—Ç–¥–µ–ª–∞: –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ "–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è..."
    "head_checked": {
        "name": "–ü—Ä–æ–≤–µ—Ä–µ–Ω—ã –ì–ü–ó–£ –Ω–∞—á–∞–ª—å–Ω–∏–∫–æ–º –æ—Ç–¥–µ–ª–∞",
        "column_ids": [5474975],
    },

    # 6. –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –ì–∞–±–∏–¥—É–ª–∏–Ω–æ–π (–ø–æ—Å–ª–µ –Ω–∞—á–∞–ª—å–Ω–∏–∫–∞ –æ—Ç–¥–µ–ª–∞): –≥—Ä–∞–¥–ø–ª–∞–Ω—ã –∏ –æ—Ç–∫–∞–∑—ã
    # –í–∞–∂–Ω–æ: 5577124 —É—á–∞—Å—Ç–≤—É–µ—Ç –∏ –∫–∞–∫ "–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –æ—Ç–∫–∞–∑—ã". –ü–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º exclusive=True.
    "gabidullina_checked": {
        "name": "–ü—Ä–æ–≤–µ—Ä–µ–Ω—ã –ì–∞–±–∏–¥—É–ª–∏–Ω–æ–π –†.–†.",
        "column_ids": [5542289, 5577124],
    },

    # 7. –ø–æ–¥–ø–∏—Å–∞–Ω—ã –≥—Ä–∞–¥–ø–ª–∞–Ω—ã: –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ "–í–Ω–µ—Å—Ç–∏ –≤ –ì–ò–°–û–ì–î (–≥—Ä–∞–¥–ø–ª–∞–Ω—ã)" (id 5474977)
    "gpzu_signed": {
        "name": "–ü–æ–¥–ø–∏—Å–∞–Ω—ã –ì–ü–ó–£",
        "column_ids": [5474977],
    },

    # 8. –≤–Ω–µ—Å–µ–Ω–æ –≤ –ì–ò–°–û–ì–î: –≥—Ä–∞–¥–ø–ª–∞–Ω—ã –∏ –æ—Ç–∫–∞–∑—ã —Ä–∞–∑–¥–µ–ª—å–Ω–æ
    "isogd_added": {
        "name": "–í–Ω–µ—Å–µ–Ω–æ –≤ –ì–ò–°–û–ì–î",
        "column_ids": {
            "gpzu": [5474978],     # –í–Ω–µ—Å—Ç–∏ –≤ –ò–°–û–ì–î –∏ –∞—Ä—Ö–∏–≤
            "refusals": [5474969], # –í–Ω–µ—Å—Ç–∏ –≤ –ò–°–û–ì–î (–æ—Ç–∫–∞–∑—ã)
        },
    },
}


def build_metric_targets(column_names: dict, metrics: dict):
    """–ú–µ—Ç—Ä–∏–∫–∏ (ID) -> —Ü–µ–ª–µ–≤—ã–µ –ù–ê–ó–í–ê–ù–ò–Ø –∫–æ–ª–æ–Ω–æ–∫ (routes —É –Ω–∞—Å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º)."""
    targets = {}
    for key, spec in metrics.items():
        col_ids = spec["column_ids"]
        if isinstance(col_ids, dict):
            sub = {}
            for subkey, ids in col_ids.items():
                sub[subkey] = {column_names[i] for i in ids if i in column_names}
            targets[key] = sub
        else:
            targets[key] = {column_names[i] for i in col_ids if i in column_names}
    return targets


def count_metrics_for_date(
    date_str: str,
    moves_store: dict,
    column_names: dict,
    metrics: dict,
    metrics_order: list,
    exclusive: bool = True
):
    """
    –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –¥–∞—Ç—É.
    –°–æ–±—ã—Ç–∏–µ = –ø–æ–ø–∞–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –≤ —Ü–µ–ª–µ–≤—É—é –∫–æ–ª–æ–Ω–∫—É (to_col_name).

    exclusive=True ‚Äî –æ–¥–Ω–æ —Å–æ–±—ã—Ç–∏–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ –æ–¥–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ (–ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É metrics_order).
    """
    stats = moves_store.get(date_str, {})
    metric_targets = build_metric_targets(column_names, metrics)

    totals_flat = defaultdict(int)
    totals_nested = defaultdict(lambda: defaultdict(int))

    for _, routes in stats.items():
        for (_, to_col), count in routes.items():
            matched = False
            for metric_key in metrics_order:
                targets = metric_targets.get(metric_key)

                if isinstance(targets, dict):
                    for subkey, target_set in targets.items():
                        if to_col in target_set:
                            totals_nested[metric_key][subkey] += count
                            matched = True
                            break
                else:
                    if to_col in targets:
                        totals_flat[metric_key] += count
                        matched = True

                if matched and exclusive:
                    break

    result_totals = {}
    for key in metrics_order:
        if key in totals_nested:
            result_totals[key] = dict(totals_nested[key])
        else:
            result_totals[key] = int(totals_flat.get(key, 0))

    return result_totals


def render_flow_report(date_str: str, totals: dict, metrics: dict) -> str:
    """Telegram-—Ç–µ–∫—Å—Ç –æ—Ç—á—ë—Ç–∞ –ø–æ –ø–æ—Ç–æ–∫—É (–±–µ–∑ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤)."""
    lines = [f"üìä –ü–æ—Ç–æ–∫ –∑–∞ {date_str}\n"]

    def add_if_nonzero(metric_key: str):
        value = totals.get(metric_key, 0)
        if isinstance(value, dict):
            return
        if value:
            lines.append(f"‚Ä¢ {metrics[metric_key]['name']}: {value}")

    for key in [
        "primary_intake",
        "rso_requests_done",
        "gpzu_prepared",
        "refusals_prepared",
        "head_checked",
        "gabidullina_checked",
        "gpzu_signed",
    ]:
        add_if_nonzero(key)

    isogd = totals.get("isogd_added", {})
    if isinstance(isogd, dict):
        gpzu = int(isogd.get("gpzu", 0))
        refusals = int(isogd.get("refusals", 0))
        if gpzu or refusals:
            lines.append("‚Ä¢ –í–Ω–µ—Å–µ–Ω–æ –≤ –ì–ò–°–û–ì–î:")
            if gpzu:
                lines.append(f"  ‚Äì –≥—Ä–∞–¥–ø–ª–∞–Ω—ã: {gpzu}")
            if refusals:
                lines.append(f"  ‚Äì –æ—Ç–∫–∞–∑—ã: {refusals}")

    # –ï—Å–ª–∏ –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º –Ω—É–ª–∏ ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
    if len(lines) == 2:
        lines.append("–î–µ–π—Å—Ç–≤–∏–π –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º –Ω–µ –±—ã–ª–æ.")

    return "\n".join(lines)


def generate_report_text_for_day(report_day: date) -> str:
    date_str = date_to_str(report_day)
    with data_lock:
        totals = count_metrics_for_date(
            date_str=date_str,
            moves_store=moves_by_date,
            column_names=COLUMN_NAMES,
            metrics=METRICS,
            metrics_order=METRICS_ORDER,
            exclusive=True
        )
    return render_flow_report(date_str, totals, METRICS)


# ==========================
#  –ê–í–¢–û-–û–¢–ü–†–ê–í–ö–ê (—Ä–∞–±–æ—á–∏–µ –¥–Ω–∏, 08:30; –≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ ‚Äî –∑–∞ –ø—è—Ç–Ω–∏—Ü—É)
# ==========================

def auto_send_daily_reports():
    print("[AUTO-REPORT] ü§ñ –ê–≤—Ç–æ-–æ—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á—ë—Ç–æ–≤ –≤–∫–ª—é—á–µ–Ω–∞: 08:30 (–ù–æ–≤–æ–∫—É–∑–Ω–µ—Ü–∫), —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –¥–Ω–∏.")
    if HOLIDAYS:
        print(f"[AUTO-REPORT] –ü—Ä–∞–∑–¥–Ω–∏–∫–∏ –∏–∑ HOLIDAYS: {len(HOLIDAYS)}")

    while True:
        now = now_nsk()
        today_d = now.date()

        if now.hour == 8 and now.minute == 30:
            # –ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ –∏ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏
            if not is_workday(today_d):
                print(f"[AUTO-REPORT] ‚õî {date_to_str(today_d)} –≤—ã—Ö–æ–¥–Ω–æ–π/–ø—Ä–∞–∑–¥–Ω–∏–∫ ‚Äî –æ—Ç—á—ë—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º.")
                time.sleep(120)
                continue

            report_day = prev_workday(today_d)
            text = generate_report_text_for_day(report_day)

            success = send_telegram_report(text)

            if success:
                print(f"[AUTO-REPORT] ‚úÖ –û—Ç—á—ë—Ç –∑–∞ {date_to_str(report_day)} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
                # –û—á–∏—â–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –¥–µ–Ω—å (–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º)
                with data_lock:
                    dstr = date_to_str(report_day)
                    if dstr in moves_by_date:
                        moves_by_date[dstr] = {}
                    persist_now()
            else:
                print(f"[AUTO-REPORT] ‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç—á—ë—Ç–∞ –∑–∞ {date_to_str(report_day)}")

            time.sleep(120)
        else:
            time.sleep(30)


# ==========================
#  WEBHOOK
# ==========================

@app.post("/gradplan_process")
async def kaiten_webhook(request: Request):
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–µ–±—Ö—É–∫–∞ –æ—Ç Kaiten.
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–∏ –∫–∞—Ä—Ç–æ—á–µ–∫ –∏ —Å–æ–±–∏—Ä–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
    """
    body = await request.json()

    if body.get("event") != "card:update":
        return {"ok": True}

    data = body.get("data", {})
    old = data.get("old", {})
    changes = data.get("changes", {})
    author = data.get("author", {})

    if "column_id" in changes:
        user_name = author.get("full_name") or author.get("username") or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
        date_key = today_str()

        old_column_id = old.get("column_id")
        new_column_id = changes["column_id"]

        old_column_name = get_column_name(old_column_id)
        new_column_name = get_column_name(new_column_id)

        with data_lock:
            if date_key not in moves_by_date:
                moves_by_date[date_key] = {}

            if user_name not in moves_by_date[date_key]:
                moves_by_date[date_key][user_name] = defaultdict(int)

            route = (old_column_name, new_column_name)
            moves_by_date[date_key][user_name][route] += 1

            persist_now()

        print(f"[MOVE] {date_key} | {user_name}: {old_column_name} (ID:{old_column_id}) ‚Üí {new_column_name} (ID:{new_column_id})")

    return {"ok": True}


# ==========================
#  –†–£–ß–ù–û–ô –û–¢–ß–Å–¢
# ==========================

@app.get("/daily_report")
def daily_report():
    """
    –û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç—á—ë—Ç –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å.
    –ï—Å–ª–∏ —Å–µ–≥–æ–¥–Ω—è –≤—ã—Ö–æ–¥–Ω–æ–π/–ø—Ä–∞–∑–¥–Ω–∏–∫ ‚Äî –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º.
    """
    today_d = now_nsk().date()
    if not is_workday(today_d):
        msg = f"‚õî –°–µ–≥–æ–¥–Ω—è {date_to_str(today_d)} –≤—ã—Ö–æ–¥–Ω–æ–π/–ø—Ä–∞–∑–¥–Ω–∏–∫ ‚Äî –æ—Ç—á—ë—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω."
        print(f"[DAILY_REPORT] {msg}")
        return {"ok": True, "skipped": True, "message": msg}

    report_day = prev_workday(today_d)
    text = generate_report_text_for_day(report_day)

    success = send_telegram_report(text)

    if success:
        with data_lock:
            dstr = date_to_str(report_day)
            if dstr in moves_by_date:
                moves_by_date[dstr] = {}
            persist_now()

    return {"ok": success, "report_day": date_to_str(report_day), "report": text}


@app.get("/test_report")
def test_report():
    """
    –¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç: –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –¥–Ω—è.
    """
    print("[TEST-REPORT] üß™ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞")

    lines = ["üß™ –¢–ï–°–¢–û–í–´–ô –û–¢–ß–Å–¢\n"]
    now = now_nsk()
    lines.append(f"üïê –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è: {now.strftime('%Y-%m-%d %H:%M:%S')} (–ù–æ–≤–æ–∫—É–∑–Ω–µ—Ü–∫)")

    dates = [(now.date() - timedelta(days=i)) for i in range(3)]
    with data_lock:
        for d in dates:
            dstr = date_to_str(d)
            stats = moves_by_date.get(dstr, {})
            if stats:
                total = sum(sum(routes.values()) for routes in stats.values())
                lines.append(f"\nüìÖ {dstr}: –≤—Å–µ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–π: {total}")
                for user, routes in stats.items():
                    lines.append(f"  üë§ {user}: {sum(routes.values())}")
            else:
                lines.append(f"\nüìÖ {dstr}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

    text = "\n".join(lines)
    success = send_telegram_report(text)
    return {"ok": success, "report": text}


# ==========================
#  STARTUP
# ==========================

@app.on_event("startup")
async def startup_event():
    global moves_by_date
    with data_lock:
        moves_by_date = load_moves_from_json()

    report_thread = threading.Thread(target=auto_send_daily_reports, daemon=True)
    report_thread.start()

    print("[STARTUP] ‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω!")
    print(f"[STARTUP] DATA_FILE={DATA_FILE}, retention={DATA_RETENTION_DAYS} days")
    if HOLIDAYS:
        print(f"[STARTUP] HOLIDAYS={len(HOLIDAYS)} –¥–∞—Ç")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
